groups:
  - name: Basic resource monitoring
    services:
      - name: Prometheus self-monitoring
        exporters:
          - rules:
            - name: Prometheus job missing
              description: A Prometheus job has disappeared
              query: 'absent(up{job="my-job"})'
              severity: warning
            - name: Prometheus target missing
              description: A Prometheus target has disappeared. An exporter might be crashed.
              query: 'up == 0'
              severity: error
            - name: Prometheus all targets missing
              description: A Prometheus job does not have living target anymore.
              query: 'count by (job) (up) == 0'
              severity: error
            - name: Prometheus configuration reload failure
              description: Prometheus configuration reload error
              query: 'prometheus_config_last_reload_successful != 1'
              severity: warning
            - name: Prometheus too many restarts
              description: Prometheus has restarted more than twice in the last 15 minutes. It might be crashlooping.
              query: 'changes(process_start_time_seconds{job=~"prometheus|pushgateway|alertmanager"}[15m]) > 2'
              severity: warning
            - name: Prometheus AlertManager configuration reload failure
              description: AlertManager configuration reload error
              query: 'alertmanager_config_last_reload_successful != 1'
              severity: warning
            - name: Prometheus AlertManager config not synced
              description: Configurations of AlertManager cluster instances are out of sync
              query: 'count(count_values("config_hash", alertmanager_config_hash)) > 1'
              severity: warning
            - name: Prometheus AlertManager E2E dead man switch
              description: Prometheus DeadManSwitch is an always-firing alert. It's used as an end-to-end test of Prometheus through the Alertmanager.
              query: 'vector(1)'
              severity: error
            - name: Prometheus not connected to alertmanager
              description: Prometheus cannot connect the alertmanager
              query: "prometheus_notifications_alertmanagers_discovered < 1"
              severity: error
            - name: Prometheus rule evaluation failures
              description: 'Prometheus encountered {{ $value }} rule evaluation failures, leading to potentially ignored alerts.'
              query: 'increase(prometheus_rule_evaluation_failures_total[3m]) > 0'
              severity: error
            - name: Prometheus template text expansion failures
              description: 'Prometheus encountered {{ $value }} template text expansion failures'
              query: 'increase(prometheus_template_text_expansion_failures_total[3m]) > 0'
              severity: error
            - name: Prometheus rule evaluation slow
              description: 'Prometheus rule evaluation took more time than the scheduled interval. I indicates a slower storage backend access or too complex query.'
              query: 'prometheus_rule_group_last_duration_seconds > prometheus_rule_group_interval_seconds'
              severity: warning
            - name: Prometheus notifications backlog
              description: The Prometheus notification queue has not been empty for 10 minutes
              query: 'min_over_time(prometheus_notifications_queue_length[10m]) > 0'
              severity: warning
            - name: Prometheus AlertManager notification failing
              description: Alertmanager is failing sending notifications
              query: 'rate(alertmanager_notifications_failed_total[1m]) > 0'
              severity: error
            - name: Prometheus target empty
              description: Prometheus has no target in service discovery
              query: 'prometheus_sd_discovered_targets == 0'
              severity: error
            - name: Prometheus target scraping slow
              description: Prometheus is scraping exporters slowly
              query: 'prometheus_target_interval_length_seconds{quantile="0.9"} > 60'
              severity: warning
            - name: Prometheus large scrape
              description: Prometheus has many scrapes that exceed the sample limit
              query: 'increase(prometheus_target_scrapes_exceeded_sample_limit_total[10m]) > 10'
              severity: warning
            - name: Prometheus target scrape duplicate
              description: Prometheus has many samples rejected due to duplicate timestamps but different values
              query: 'increase(prometheus_target_scrapes_sample_duplicate_timestamp_total[5m]) > 0'
              severity: warning
            - name: Prometheus TSDB checkpoint creation failures
              description: 'Prometheus encountered {{ $value }} checkpoint creation failures'
              query: 'increase(prometheus_tsdb_checkpoint_creations_failed_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB checkpoint deletion failures
              description: 'Prometheus encountered {{ $value }} checkpoint deletion failures'
              query: 'increase(prometheus_tsdb_checkpoint_deletions_failed_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB compactions failed
              description: 'Prometheus encountered {{ $value }} TSDB compactions failures'
              query: 'increase(prometheus_tsdb_compactions_failed_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB head truncations failed
              description: 'Prometheus encountered {{ $value }} TSDB head truncation failures'
              query: 'increase(prometheus_tsdb_head_truncations_failed_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB reload failures
              description: 'Prometheus encountered {{ $value }} TSDB reload failures'
              query: 'increase(prometheus_tsdb_reloads_failures_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB WAL corruptions
              description: 'Prometheus encountered {{ $value }} TSDB WAL corruptions'
              query: 'increase(prometheus_tsdb_wal_corruptions_total[3m]) > 0'
              severity: error
            - name: Prometheus TSDB WAL truncations failed
              description: 'Prometheus encountered {{ $value }} TSDB WAL truncation failures'
              query: 'increase(prometheus_tsdb_wal_truncations_failed_total[3m]) > 0'
              severity: error

      - name: Host and hardware
        exporters:
          - name: node-exporter
            doc_url: https://github.com/prometheus/node_exporter
            rules:
              - name: Host out of memory
                description: Node memory is filling up (< 10% left)
                query: "node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10"
                severity: warning
              - name: Host memory under memory pressure
                description: The node is under heavy memory pressure. High rate of major page faults
                query: "rate(node_vmstat_pgmajfault[1m]) > 1000"
                severity: warning
              - name: Host unusual network throughput in
                description: Host network interfaces are probably receiving too much data (> 100 MB/s)
                query: "sum by (instance) (irate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100"
                severity: warning
              - name: Host unusual network throughput out
                description: Host network interfaces are probably sending too much data (> 100 MB/s)
                query: "sum by (instance) (irate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100"
                severity: warning
              - name: Host unusual disk read rate
                description: Disk is probably reading too much data (> 50 MB/s)
                query: "sum by (instance) (irate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50"
                severity: warning
              - name: Host unusual disk write rate
                description: Disk is probably writing too much data (> 50 MB/s)
                query: "sum by (instance) (irate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50"
                severity: warning
              - name: Host out of disk space
                description: Disk is almost full (< 10% left)
                query: '(node_filesystem_avail_bytes{mountpoint="/rootfs"}  * 100) / node_filesystem_size_bytes{mountpoint="/rootfs"} < 10'
                severity: warning
              - name: Host disk will fill in 4 hours
                description: Disk will fill in 4 hours at current write rate
                query: 'predict_linear(node_filesystem_free_bytes{fstype!~"tmpfs"}[1h], 4 * 3600) < 0'
                severity: warning
              - name: Host out of inodes
                description: Disk is almost running out of available inodes (< 10% left)
                query: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint ="/rootfs"} * 100 < 10'
                severity: warning
              - name: Host unusual disk read latency
                description: Disk latency is growing (read operations > 100ms)
                query: "rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 100"
                severity: warning
              - name: Host unusual disk write latency
                description: Disk latency is growing (write operations > 100ms)
                query: "rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 100"
                severity: warning
              - name: Host high CPU load
                description: CPU load is > 80%
                query: '100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80'
                severity: warning
              - name: Host context switching
                description: Context switching is growing on node (> 1000 / s)
                query: "rate(node_context_switches_total[5m]) > 1000"
                severity: warning
                comments: |
                  1000 context switches is an arbitrary number.
                  Alert threshold depends on nature of application.
                  Please read: https://github.com/samber/awesome-prometheus-alerts/issues/58
              - name: Host swap is filling up
                description: Swap is filling up (>80%)
                query: "(1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80"
                severity: warning
              - name: Host SystemD service crashed
                description: "SystemD service crashed"
                query: 'node_systemd_unit_state{state="failed"} == 1'
                severity: warning
              - name: Host physical component too hot
                description: "Physical hardware component too hot"
                query: "node_hwmon_temp_celsius > 75"
                severity: warning
              - name: Host node overtemperature alarm
                description: "Physical node temperature alarm triggered"
                query: "node_hwmon_temp_alarm == 1"
                severity: error
              - name: Host RAID array got inactive
                description: 'RAID array {{ $labels.device }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.'
                query: 'node_md_state{state="inactive"} > 0'
                severity: error
              - name: Host RAID disk failure
                description: 'At least one device in RAID array on {{ $labels.instance }} failed. Array {{ $labels.md_device }} needs attention and possibly a disk swap'
                query: 'node_md_disks{state="fail"} > 0'
                severity: warning
              - name: Host kernel version deviations
                description: Different kernel versions are running
                query: 'count(sum(label_replace(node_uname_info, "kernel", "$1", "release", "([0-9]+.[0-9]+.[0-9]+).*")) by (kernel)) > 1'
                severity: warning
              - name: Host OOM kill detected
                description: OOM kill detected
                query: 'increase(node_vmstat_oom_kill[30m]) > 1'
                severity: warning


  - name: Databases and brokers
    services:
      - name: PostgreSQL
        exporters:
          - name: wrouesnel/postgres_exporter
            doc_url: https://github.com/wrouesnel/postgres_exporter/
            rules:
              - name: Postgresql down
                description: Postgresql instance is down
                query: "pg_up == 0"
                severity: error
              - name: Postgresql restarted
                description: Postgresql restarted
                query: "time() - pg_postmaster_start_time_seconds < 60"
                severity: error
              - name: Postgresql exporter error
                description: Postgresql exporter is showing errors. A query may be buggy in query.yaml
                query: 'pg_exporter_last_scrape_error > 0'
                severity: warning
              - name: Postgresql replication lag
                description: PostgreSQL replication lag is going up (> 10s)
                query: '(pg_replication_lag > 10 and ON(instance) (pg_replication_is_replica == 1)'
                severity: warning
              - name: Postgresql table not vaccumed
                description: Table has not been vaccum for 24 hours
                query: "time() - pg_stat_user_tables_last_autovacuum > 60 * 60 * 24"
                severity: warning
              - name: Postgresql table not analyzed
                description: Table has not been analyzed for 24 hours
                query: "time() - pg_stat_user_tables_last_autoanalyze > 60 * 60 * 24"
                severity: warning
              - name: Postgresql too many connections
                description: PostgreSQL instance has too many connections
                query: 'sum by (datname) (pg_stat_activity_count{datname!~"template.*|postgres"}) > pg_settings_max_connections * 0.9'
                severity: warning
              - name: Postgresql not enough connections
                description: PostgreSQL instance should have more connections (> 5)
                query: 'sum by (datname) (pg_stat_activity_count{datname!~"template.*|postgres"}) < 5'
                severity: warning
              - name: Postgresql dead locks
                description: PostgreSQL has dead-locks
                query: 'rate(pg_stat_database_deadlocks{datname!~"template.*|postgres"}[1m]) > 0'
                severity: warning
              - name: Postgresql slow queries
                description: PostgreSQL executes slow queries
                query: 'pg_slow_queries > 0'
                severity: warning
              - name: Postgresql high rollback rate
                description: Ratio of transactions being aborted compared to committed is > 2 %
                query: 'rate(pg_stat_database_xact_rollback{datname!~"template.*"}[3m]) / rate(pg_stat_database_xact_commit{datname!~"template.*"}[3m]) > 0.02'
                severity: warning
              - name: Postgresql commit rate low
                description: Postgres seems to be processing very few transactions
                query: 'rate(pg_stat_database_xact_commit[1m]) < 10'
                severity: error
              - name: Postgresql low XID consumption
                description: Postgresql seems to be consuming transaction IDs very slowly
                query: 'rate(pg_txid_current[1m]) < 5'
                severity: warning
              - name: Postgresqllow XLOG consumption
                description: Postgres seems to be consuming XLOG very slowly
                query: 'rate(pg_xlog_position_bytes[1m]) < 100'
                severity: warning
              - name: Postgresql WALE replication stopped
                description: WAL-E replication seems to be stopped
                query: 'rate(pg_xlog_position_bytes[1m]) == 0'
                severity: error
              - name: Postgresql high rate statement timeout
                description: Postgres transactions showing high rate of statement timeouts
                query: 'rate(postgresql_errors_total{type="statement_timeout"}[5m]) > 3'
                severity: error
              - name: Postgresql high rate deadlock
                description: Postgres detected deadlocks
                query: 'rate(postgresql_errors_total{type="deadlock_detected"}[1m]) * 60 > 1'
                severity: error
              - name: Postgresql replication lab bytes
                description: Postgres Replication lag (in bytes) is high
                query: '(pg_xlog_position_bytes and pg_replication_is_replica == 0) - GROUP_RIGHT(instance) (pg_xlog_position_bytes and pg_replication_is_replica == 1) > 1e+09'
                severity: error
              - name: Postgresql unused replication slot
                description: Unused Replication Slots
                query: 'pg_replication_slots_active == 0'
                severity: warning
              - name: Postgresql too many dead tuples
                description: PostgreSQL dead tuples is too large
                query: '((pg_stat_user_tables_n_dead_tup > 10000) / (pg_stat_user_tables_n_live_tup + pg_stat_user_tables_n_dead_tup)) >= 0.1 unless ON(instance) (pg_replication_is_replica == 1)'
                severity: warning
              - name: Postgresql split brain
                description: Split Brain, too many primary Postgresql databases in read-write mode
                query: 'count(pg_replication_is_replica == 0) != 1'
                severity: error
              - name: Postgresql promoted node
                description: Postgresql standby server has been promoted as primary node
                query: 'pg_replication_is_replica and changes(pg_replication_is_replica[1m]) > 0'
                severity: warning
              - name: Postgresql configuration changed
                description: Postgres Database configuration change has occurred
                query: '{__name__=~"pg_settings_.*"} != ON(__name__) {__name__=~"pg_settings_([^t]|t[^r]|tr[^a]|tra[^n]|tran[^s]|trans[^a]|transa[^c]|transac[^t]|transact[^i]|transacti[^o]|transactio[^n]|transaction[^_]|transaction_[^r]|transaction_r[^e]|transaction_re[^a]|transaction_rea[^d]|transaction_read[^_]|transaction_read_[^o]|transaction_read_o[^n]|transaction_read_on[^l]|transaction_read_onl[^y]).*"} OFFSET 5m'
                severity: warning
              - name: Postgresql SSL compression active
                description: Database connections with SSL compression enabled. This may add significant jitter in replication delay. Replicas should turn off SSL compression via `sslcompression=0` in `recovery.conf`.
                query: 'sum(pg_stat_ssl_compression) > 0'
                severity: error
              - name: Postgresql too many locks acquired
                description: Too many locks acquired on the database. If this alert happens frequently, we may need to increase the postgres setting max_locks_per_transaction.
                query: '((sum (pg_locks_count)) / (pg_settings_max_locks_per_transaction * pg_settings_max_connections)) > 0.20'
                severity: error

      - name: PGBouncer
        exporters:
          - name: spreaker/prometheus-pgbouncer-exporter
            doc_url: https://github.com/spreaker/prometheus-pgbouncer-exporter
            rules:
              - name: PGBouncer active connectinos
                description: PGBouncer pools are filling up
                query: 'pgbouncer_pools_server_active_connections > 200'
                severity: warning
              - name: PGBouncer errors
                description: PGBouncer is logging errors. This may be due to a a server restart or an admin typing commands at the pgbouncer console.
                query: 'increase(pgbouncer_errors_count{errmsg!="server conn crashed?"}[5m]) > 10'
                severity: warning
              - name: PGBouncer max connections
                description: The number of PGBouncer client connections has reached max_client_conn.
                query: 'rate(pgbouncer_errors_count{errmsg="no more connections allowed (max_client_conn)"}[1m]) > 0'
                severity: error

      - name: Redis
        exporters:
          - name: oliver006/redis_exporter
            doc_url: https://github.com/oliver006/redis_exporter
            rules:
              - name: Redis down
                description: Redis instance is down
                query: "redis_up == 0"
                severity: error
              - name: Redis missing master
                description: Redis cluster has no node marked as master.
                query: 'count(redis_instance_info{role="master"}) == 0'
                severity: error
              - name: Redis too many masters
                description: Redis cluster has too many nodes marked as master.
                query: 'count(redis_instance_info{role="master"}) > 1'
                severity: error
              - name: Redis disconnected slaves
                description: Redis not replicating for all slaves. Consider reviewing the redis replication status.
                query: 'count without (instance, job) (redis_connected_slaves) - sum without (instance, job) (redis_connected_slaves) - 1 > 1'
                severity: error
              - name: Redis replication broken
                description: Redis instance lost a slave
                query: "delta(redis_connected_slaves[1m]) < 0"
                severity: error
              - name: Redis cluster flapping
                description: Changes have been detected in Redis replica connection. This can occur when replica nodes lose connection to the master and reconnect (a.k.a flapping).
                query: 'changes(redis_connected_slaves[5m]) > 2'
                severity: error
              - name: Redis missing backup
                description: Redis has not been backuped for 24 hours
                query: "time() - redis_rdb_last_save_timestamp_seconds > 60 * 60 * 24"
                severity: error
              - name: Redis out of memory
                description: Redis is running out of memory (> 90%)
                query: "redis_memory_used_bytes / redis_total_system_memory_bytes * 100 > 90"
                severity: warning
              - name: Redis too many connections
                description: Redis instance has too many connections
                query: "redis_connected_clients > 100"
                severity: warning
              - name: Redis not enough connections
                description: Redis instance should have more connections (> 5)
                query: "redis_connected_clients < 5"
                severity: warning
              - name: Redis rejected connections
                description: Some connections to Redis has been rejected
                query: "increase(redis_rejected_connections_total[1m]) > 0"
                severity: error

      - name: RabbitMQ
        exporters:
          - name: kbudde/rabbitmq-exporter
            doc_url: https://github.com/kbudde/rabbitmq_exporter
            rules:
              - name: Rabbitmq down
                description: RabbitMQ node down
                query: "rabbitmq_up == 0"
                severity: error
              - name: Rabbitmq cluster down
                description: Less than 3 nodes running in RabbitMQ cluster
                query: "sum(rabbitmq_running) < 3"
                severity: error
              - name: Rabbitmq cluster partition
                description: Cluster partition
                query: "rabbitmq_partitions > 0"
                severity: error
              - name: Rabbitmq out of memory
                description: Memory available for RabbmitMQ is low (< 10%)
                query: "rabbitmq_node_mem_used / rabbitmq_node_mem_limit * 100 > 90"
                severity: warning
              - name: Rabbitmq too many connections
                description: RabbitMQ instance has too many connections (> 1000)
                query: "rabbitmq_connectionsTotal > 1000"
                severity: warning
              - name: Rabbitmq dead letter queue filling up
                description: Dead letter queue is filling up (> 10 msgs)
                query: 'rabbitmq_queue_messages{queue="my-dead-letter-queue"} > 10'
                severity: error
              - name: Rabbitmq too many messages in queue
                description: Queue is filling up (> 1000 msgs)
                query: 'rabbitmq_queue_messages_ready{queue="my-queue"} > 1000'
                severity: warning
              - name: Rabbitmq slow queue consuming
                description: Queue messages are consumed slowly (> 60s)
                query: 'time() - rabbitmq_queue_head_message_timestamp{queue="my-queue"} > 60'
                severity: warning
              - name: Rabbitmq no consumer
                description: Queue has no consumer
                query: "rabbitmq_queue_consumers == 0"
                severity: error
              - name: Rabbitmq too many consumers
                description: Queue should have only 1 consumer
                query: "rabbitmq_queue_consumers > 1"
                severity: error
              - name: Rabbitmq unactive exchange
                description: Exchange receive less than 5 msgs per second
                query: 'rate(rabbitmq_exchange_messages_published_in_total{exchange="my-exchange"}[1m]) < 5'
                severity: warning

      - name: Elasticsearch
        exporters:
          - name: justwatchcom/elasticsearch_exporter
            doc_url: https://github.com/justwatchcom/elasticsearch_exporter
            rules:
              - name: Elasticsearch Heap Usage Too High
                description: "The heap usage is over 90% for 5m"
                query: '(elasticsearch_jvm_memory_used_bytes{area="heap"} / elasticsearch_jvm_memory_max_bytes{area="heap"}) * 100 > 90'
                severity: error
              - name: Elasticsearch Heap Usage warning
                description: "The heap usage is over 80% for 5m"
                query: '(elasticsearch_jvm_memory_used_bytes{area="heap"} / elasticsearch_jvm_memory_max_bytes{area="heap"}) * 100 > 80'
                severity: warning
              - name: Elasticsearch disk space low
                description: The disk usage is over 80%
                query: 'elasticsearch_filesystem_data_available_bytes / elasticsearch_filesystem_data_size_bytes * 100 < 20'
                severity: warning
              - name: Elasticsearch disk out of space
                description: The disk usage is over 90%
                query: 'elasticsearch_filesystem_data_available_bytes / elasticsearch_filesystem_data_size_bytes * 100 < 10'
                severity: error
              - name: Elasticsearch Cluster Red
                description: Elastic Cluster Red status
                query: 'elasticsearch_cluster_health_status{color="red"} == 1'
                severity: error
              - name: Elasticsearch Cluster Yellow
                description: Elastic Cluster Yellow status
                query: 'elasticsearch_cluster_health_status{color="yellow"} == 1'
                severity: warning
              - name: Elasticsearch Healthy Nodes
                description: "Number Healthy Nodes less then number_of_nodes"
                query: "elasticsearch_cluster_health_number_of_nodes < number_of_nodes"
                severity: error
              - name: Elasticsearch Healthy Data Nodes
                description: "Number Healthy Data Nodes less then number_of_data_nodes"
                query: "elasticsearch_cluster_health_number_of_data_nodes < number_of_data_nodes"
                severity: error
              - name: Elasticsearch relocation shards
                description: "Number of relocation shards for 20 min"
                query: "elasticsearch_cluster_health_relocating_shards > 0"
                severity: error
              - name: Elasticsearch initializing shards
                description: "Number of initializing shards for 10 min"
                query: "elasticsearch_cluster_health_initializing_shards > 0"
                severity: warning
              - name: Elasticsearch unassigned shards
                description: "Number of unassigned shards for 2 min"
                query: "elasticsearch_cluster_health_unassigned_shards > 0"
                severity: error
              - name: Elasticsearch pending tasks
                description: "Number of pending tasks for 10 min. Cluster works slowly."
                query: "elasticsearch_cluster_health_number_of_pending_tasks > 0"
                severity: warning
              - name: Elasticsearch no new documents
                description: No new documents for 10 min!
                query: 'rate(elasticsearch_indices_docs{es_data_node="true"}[10m]) < 1'
                severity: warning

      - name: Zookeeper
        exporters:
          - name: cloudflare/kafka_zookeeper_exporter
            doc_url: https://github.com/cloudflare/kafka_zookeeper_exporter
            rules:

      - name: Kafka
        exporters:
          - name: danielqsj/kafka_exporter
            doc_url: https://github.com/danielqsj/kafka_exporter
            rules:
              - name: Kafka topics replicas
                description: Kafka topic in-sync partition
                query: "sum(kafka_topic_partition_in_sync_replica) by (topic) < 3"
                severity: error
              - name: Kafka consumers group
                description: Kafka consumers group
                query: "sum(kafka_consumergroup_lag) by (consumergroup) > 50"
                severity: error


  - name: Reverse proxies and load balancers
    services:
      - name: Nginx
        exporters:
          - name: nginx-lua-prometheus
            doc_url: https://github.com/knyar/nginx-lua-prometheus
            rules:
              - name: Nginx high HTTP 4xx error rate
                description: Too many HTTP requests with status 4xx (> 5%)
                query: 'sum(rate(nginx_http_requests_total{status=~"^4.."}[1m])) / sum(rate(nginx_http_requests_total[1m])) * 100 > 5'
                severity: error
              - name: Nginx high HTTP 5xx error rate
                description: Too many HTTP requests with status 5xx (> 5%)
                query: 'sum(rate(nginx_http_requests_total{status=~"^5.."}[1m])) / sum(rate(nginx_http_requests_total[1m])) * 100 > 5'
                severity: error
              - name: Nginx latency high
                description: Nginx p99 latency is higher than 10 seconds
                query: 'histogram_quantile(0.99, sum(rate(nginx_http_request_duration_seconds_bucket[30m])) by (host, node)) > 10'
                severity: warning

      - name: HaProxy
        exporters:
          - name: Embedded exporter (HAProxy >= v2)
            doc_url: https://github.com/haproxy/haproxy/tree/master/contrib/prometheus-exporter
            rules:
          - name: prometheus/haproxy_exporter (HAProxy < v2)
            doc_url: https://github.com/prometheus/haproxy_exporter
            rules:
              - name: HAProxy down
                description: HAProxy down
                query: 'haproxy_up = 0'
                severity: error
              - name: HAProxy high HTTP 4xx error rate backend
                description: Too many HTTP requests with status 4xx (> 5%) on backend {{ $labels.fqdn }}/{{ $labels.backend }}
                query: 'sum by (backend) irate(haproxy_server_http_responses_total{code="4xx"}[1m]) / sum by (backend) irate(haproxy_server_http_responses_total{}[1m]) * 100 > 5'
                severity: error
              - name: HAProxy high HTTP 4xx error rate backend
                description: Too many HTTP requests with status 5xx (> 5%) on backend {{ $labels.fqdn }}/{{ $labels.backend }}
                query: 'sum by (backend) irate(haproxy_server_http_responses_total{code="5xx"}[1m]) / sum by (backend) irate(haproxy_server_http_responses_total{}[1m]) * 100 > 5'
                severity: error
              - name: HAProxy high HTTP 4xx error rate server
                description: Too many HTTP requests with status 4xx (> 5%) on server {{ $labels.server }}
                query: 'sum by (server) irate(haproxy_server_http_responses_total{code="4xx"}[1m]) / sum by (backend) irate(haproxy_server_http_responses_total{}[1m]) * 100 > 5'
                severity: error
              - name: HAProxy high HTTP 5xx error rate server
                description: Too many HTTP requests with status 5xx (> 5%) on server {{ $labels.server }}
                query: 'sum by (server) irate(haproxy_server_http_responses_total{code="5xx"}[1m]) / sum by (backend) irate(haproxy_server_http_responses_total{}[1m]) * 100 > 5'
                severity: error
              - name: HAProxy backend connection errors
                description: Too many connection errors to {{ $labels.fqdn }}/{{ $labels.backend }} backend (> 5%). Request throughput may be to high.
                query: 'sum by (backend) rate(haproxy_backend_connection_errors_total[1m]) * 100 > 5'
                severity: error
              - name: HAProxy server response errors
                description: Too many response errors to {{ $labels.server }} server (> 5%).
                query: 'sum by (server) rate(haproxy_server_response_errors_total[1m]) * 100 > 5'
                severity: error
              - name: HAProxy server connection errors
                description: Too many connection errors to {{ $labels.server }} server (> 5%). Request throughput may be to high.
                query: 'sum by (server) rate(haproxy_server_connection_errors_total[1m]) * 100 > 5'
                severity: error
              - name: HAProxy backend max active session
                description: HAproxy backend {{ $labels.fqdn }}/{{ $labels.backend }} is reaching session limit (> 80%).
                query: 'avg_over_time((sum by (backend) (haproxy_server_max_sessions) / sum by (backend) (haproxy_server_limit_sessions)) [2m]) * 100 > 80'
                severity: warning
              - name: HAProxy pending requests
                description: Some HAProxy requests are pending on {{ $labels.fqdn }}/{{ $labels.backend }} backend
                query: 'sum by (backend) haproxy_backend_current_queue > 0'
                severity: warning
              - name: HAProxy HTTP slowing down
                description: Average request time is increasing
                query: 'avg by (backend) (haproxy_backend_http_total_time_average_seconds) > 2'
                severity: warning
              - name: HAProxy retry high
                description: High rate of retry on {{ $labels.fqdn }}/{{ $labels.backend }} backend
                query: 'rate(sum by (backend) (haproxy_backend_retry_warnings_total)) > 10'
                severity: warning
              - name: HAProxy backend down
                description: HAProxy backend is down
                query: 'haproxy_backend_up = 0'
                severity: error
              - name: HAProxy server down
                description: HAProxy server is down
                query: 'haproxy_server_up = 0'
                severity: error
              - name: HAProxy frontend security blocked requests
                description: HAProxy is blocking requests for security reason
                query: 'rate(sum by (frontend) (haproxy_frontend_requests_denied_total)) > 10'
                severity: warning
              - name: HAProxy server healthcheck failure
                description: Some server healthcheck are failing on {{ $labels.server }}
                query: 'increase(haproxy_server_check_failures_total) > 0'
                severity: warning
